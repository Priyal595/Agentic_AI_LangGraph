{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab734c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot - Chatting, RAG, Tools, UI, Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91f298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b8d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea12e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "\n",
    "def chat_node(state: ChatState):\n",
    "\n",
    "    # take user query from state\n",
    "    messages = state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # response store state\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "590b247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('chat_node', chat_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node', END)\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fb041d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001CBE822E600>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9a7db5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OllamaEndpointNotFoundError",
     "evalue": "Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull llama3:8b-instruct-q4_K_M`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOllamaEndpointNotFoundError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m initial_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m: [HumanMessage(content=\u001b[33m'\u001b[39m\u001b[33mWhat is the capital of india\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mchat_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      7\u001b[39m messages = state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# send to llm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# response store state\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m     **kwargs: Any,\n\u001b[32m    273\u001b[39m ) -> ChatResult:\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    275\u001b[39m \n\u001b[32m    276\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    299\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    300\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    215\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     **kwargs: Any,\n\u001b[32m    220\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    221\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    187\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    188\u001b[39m     **kwargs: Any,\n\u001b[32m    189\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m     payload = {\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    193\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agentic_AI\\myvenv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:266\u001b[39m, in \u001b[36m_OllamaCommon._create_stream\u001b[39m\u001b[34m(self, api_url, payload, stop, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m OllamaEndpointNotFoundError(\n\u001b[32m    267\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOllama call failed with status code 404. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    268\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMaybe your model is not found \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand you should pull the model with `ollama pull \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m         )\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    272\u001b[39m         optional_detail = response.text\n",
      "\u001b[31mOllamaEndpointNotFoundError\u001b[39m: Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull llama3:8b-instruct-q4_K_M`.",
      "During task with name 'chat_node' and id 'c9f6204f-ef47-6545-c506-2522d594d100'"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'messages': [HumanMessage(content='What is the capital of india')]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
